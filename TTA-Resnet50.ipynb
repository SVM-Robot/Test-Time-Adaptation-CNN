{"cells":[{"cell_type":"markdown","metadata":{"id":"-Zm3Yu4b73da"},"source":["# Test Time Adaptation on a CNN (ResNet50)"]},{"cell_type":"markdown","metadata":{"id":"3RfrTlHY73df"},"source":["In this project we implement a technique to improve the performance of a pretrained model at test time. This technique is called **Test Time Adaptation**.\n","\n","Test Time Adaptation adjusts the model parameters during the test phase, leveraging the test data itself to enhance the model's predictions."]},{"cell_type":"markdown","metadata":{"id":"MhFZSdpc73dh"},"source":["## Dataset\n","The dataset we use is the *Imagenet-V2 matched frequency* dataset. This dataset is composed of 10000 images divided in 1000 classes.\n","\n","The function `CustomImageFolder` is used to correct the wrong naming of the classes caused by the original ImageFolder function.\n","\n","Then:\n","- We import the full dataset from the files.\n","- We decide the number of samples to select from the dataset.\n","- We create a subset of the full dataset by sampling randomly from the full dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aWwGa2h98bID"},"outputs":[],"source":["!wget https://huggingface.co/datasets/vaishaal/ImageNetV2/resolve/main/imagenetv2-matched-frequency.tar.gz\n","!tar -xf imagenetv2-matched-frequency.tar.gz\n","!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSZN30u_73di"},"outputs":[],"source":["# Path to dataset\n","dataset_path = 'imagenetv2-matched-frequency-format-val'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jAkEL_oC73dt"},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","\n","from torch.utils.data import Dataset\n","from PIL import Image\n","\n","# Customization of the class ImageFolder to import the real name of the classes of Imagenet-v2\n","class CustomImageFolder(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        self.transform = transform\n","        self.classes = sorted(os.listdir(root_dir))\n","        self.class_to_idx = {cls_name: int(cls_name) for cls_name in self.classes}\n","        self.image_paths = []\n","        self.labels = []\n","\n","        for cls_name in self.classes:\n","            cls_dir = os.path.join(root_dir, cls_name)\n","            for img_name in os.listdir(cls_dir):\n","                img_path = os.path.join(cls_dir, img_name)\n","                self.image_paths.append(img_path)\n","                self.labels.append(self.class_to_idx[cls_name])\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img_path = self.image_paths[idx]\n","        image = Image.open(img_path).convert('RGB')\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","# Import the full dataset from the files\n","full_dataset = CustomImageFolder(root_dir=dataset_path)\n","\n","# Decide the number of sample to use for the test and create a random subset\n","num_samples = 3000\n","np.random.seed(0)\n","indices = np.random.choice(len(full_dataset), num_samples, replace=False)\n","subset_dataset = torch.utils.data.Subset(full_dataset, indices)"]},{"cell_type":"markdown","metadata":{"id":"bxmNNxge73dy"},"source":["## Model\n","We load the pretrained *Resnet50d* model from *Timm*.\n","\n","This model features:\n","- ReLU activations\n","- 3-layer stem of 3x3 convolutions with pooling\n","- 2x2 average pool + 1x1 convolution shortcut downsample\n","- Trained on ImageNet-1k"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pV7wwndY73d0"},"outputs":[],"source":["# !pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LXgSwyln73d6"},"outputs":[],"source":["import timm\n","\n","# Load the Resnet50d model from timm\n","model = timm.create_model('resnet50d', pretrained=True)\n","# Save the initial state of the weights\n","initial_state = model.state_dict()"]},{"cell_type":"markdown","metadata":{"id":"GZEck20673d7"},"source":["At each iteration we reset the network. We create a function to load the initial state of the model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pAuOFbED73d8"},"outputs":[],"source":["# Function to reset the state of the model to a saved initial state\n","def reset_model(model, initial_state):\n","    model.load_state_dict(initial_state)"]},{"cell_type":"markdown","metadata":{"id":"H1jgp8Xe73d9"},"source":["## Preprocess the data\n","\n","We define three sets of transformations:\n","- `preprocess_step1_test` does the resizing and cropping for the test function.\n","- `preprocess_step1` does a random resized crop and a random horizontal flip with probability of 0.5 for the adapt function.\n","- `preprocess_step2` converts the image to a tensor and then perform a normalization.\n","\n","These transformations are used for correctly feeding the images to the test and adapt functions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-WjEuSnF73d9"},"outputs":[],"source":["from torchvision import transforms\n","\n","preprocess_step1_test = transforms.Compose([\n","    transforms.Resize(256, antialias=True),\n","    transforms.CenterCrop(224)\n","])\n","\n","preprocess_step1 = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip()\n","])\n","\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","preprocess_step2 = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])"]},{"cell_type":"markdown","metadata":{"id":"9er8Tvda73d9"},"source":["## Augmentations"]},{"cell_type":"markdown","metadata":{"id":"2KRrYLGN73d9"},"source":["We define a set of augmentations.\n","These augmentations are taken from the [official MEMO implementation](https://github.com/zhangmarvin/memo)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4R3S_TA73d9"},"outputs":[],"source":["from PIL import ImageOps\n","\n","def autocontrast(pil_img, level=None):\n","    return ImageOps.autocontrast(pil_img)\n","\n","def equalize(pil_img, level=None):\n","    return ImageOps.equalize(pil_img)\n","\n","def rotate(pil_img, level):\n","    degrees = int_parameter(rand_lvl(level), 30)\n","    if np.random.uniform() > 0.5:\n","        degrees = -degrees\n","    return pil_img.rotate(degrees, resample=Image.BILINEAR, fillcolor=128)\n","\n","def solarize(pil_img, level):\n","    level = int_parameter(rand_lvl(level), 256)\n","    return ImageOps.solarize(pil_img, 256 - level)\n","\n","def shear_x(pil_img, level):\n","    level = float_parameter(rand_lvl(level), 0.3)\n","    if np.random.uniform() > 0.5:\n","        level = -level\n","    return pil_img.transform((224, 224), Image.AFFINE, (1, level, 0, 0, 1, 0), resample=Image.BILINEAR, fillcolor=128)\n","\n","def shear_y(pil_img, level):\n","    level = float_parameter(rand_lvl(level), 0.3)\n","    if np.random.uniform() > 0.5:\n","        level = -level\n","    return pil_img.transform((224, 224), Image.AFFINE, (1, 0, 0, level, 1, 0), resample=Image.BILINEAR, fillcolor=128)\n","\n","def translate_x(pil_img, level):\n","    level = int_parameter(rand_lvl(level), 224 / 3)\n","    if np.random.random() > 0.5:\n","        level = -level\n","    return pil_img.transform((224, 224), Image.AFFINE, (1, 0, level, 0, 1, 0), resample=Image.BILINEAR, fillcolor=128)\n","\n","def translate_y(pil_img, level):\n","    level = int_parameter(rand_lvl(level), 224 / 3)\n","    if np.random.random() > 0.5:\n","        level = -level\n","    return pil_img.transform((224, 224), Image.AFFINE, (1, 0, 0, 0, 1, level), resample=Image.BILINEAR, fillcolor=128)\n","\n","def posterize(pil_img, level):\n","    level = int_parameter(rand_lvl(level), 4)\n","    return ImageOps.posterize(pil_img, 4 - level)\n","\n","def int_parameter(level, maxval):\n","    \"\"\"Helper function to scale `val` between 0 and maxval .\n","    Args:\n","    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n","    maxval: Maximum value that the operation can have. This will be scaled\n","      to level/PARAMETER_MAX.\n","    Returns:\n","    An int that results from scaling `maxval` according to `level`.\n","    \"\"\"\n","    return int(level * maxval / 10)\n","\n","def float_parameter(level, maxval):\n","    \"\"\"Helper function to scale `val` between 0 and maxval .\n","    Args:\n","    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n","    maxval: Maximum value that the operation can have. This will be scaled\n","      to level/PARAMETER_MAX.\n","    Returns:\n","    A float that results from scaling `maxval` according to `level`.\n","    \"\"\"\n","    return float(level) * maxval / 10.\n","\n","# Function to compute a random level of strength to pass to the augmentations\n","def rand_lvl(n):\n","    return np.random.uniform(low=0.1, high=n)\n","\n","augmentations = [\n","    autocontrast,\n","    equalize,\n","    lambda x: rotate(x, 1),\n","    lambda x: solarize(x, 1),\n","    lambda x: shear_x(x, 1),\n","    lambda x: shear_y(x, 1),\n","    lambda x: translate_x(x, 1),\n","    lambda x: translate_y(x, 1),\n","    lambda x: posterize(x, 1),\n","]"]},{"cell_type":"markdown","metadata":{"id":"JafRm2zU73d-"},"source":["We then define the `_single_aug` function to compute a single augmentation.\n","This function takes as input an image and applies an augmentation chosen randomly from the augmentations set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkWGkWLr73d-"},"outputs":[],"source":["# Given a sample, computes a random augmentation from the augmentations set and then returns the augmented sample\n","def _single_aug(x_orig):\n","    x_orig = preprocess_step1(x_orig)\n","    x_aug = x_orig.copy()\n","    x_aug = np.random.choice(augmentations)(x_aug)\n","    x_aug = preprocess_step2(x_aug)\n","    return x_aug"]},{"cell_type":"markdown","metadata":{"id":"4vw7y5uL73d-"},"source":["The `compute_n_aug` function is used to adaptively decide how many augmentations to compute per sample. If the initial confidence is low we compute more augmentations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R75g7Ota73d-"},"outputs":[],"source":["import math\n","\n","# If adaptive_augmentation_strength is True, then we return a number of augmentations inversely proportional to the confidence of the model\n","def compute_n_aug(conf_sample_clean, n_aug_max, adaptive_augmentation_strength):\n","    if adaptive_augmentation_strength:\n","        n_aug = math.ceil((n_aug_max * (1-conf_sample_clean))+3)\n","    else:\n","        n_aug = n_aug_max\n","    return n_aug"]},{"cell_type":"markdown","metadata":{"id":"wTeSILjI73d_"},"source":["## Adapt and Test functions"]},{"cell_type":"markdown","metadata":{"id":"_R0YemSX73d_"},"source":["### Adapt function\n","\n","The `adapt_single` function is used to compute the augmentations from an original sample, stack the multiple images (original and augmented) into a single tensor and then compute the output of the model.\n","Then the function computes the marginal entropy loss and the gradient, and it updates the model weights with the optimizer to minimize the loss."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dFnWM_kn73d_"},"outputs":[],"source":["# We set the device to cuda if it is available, otherwise we set it to cpu\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"490tforb73eA"},"outputs":[],"source":["# Transformation function to use\n","tr_transforms = _single_aug\n","\n","# Function for updating the model by computing the gradient on a set of augmented samples\n","def adapt_single(model, image, optimizer, criterion, conf_sample_clean, n_aug_max, adaptive_augmentation_strength=False):\n","\n","    model.eval()\n","    # Compute the number of augmentations to perform\n","    n_aug = compute_n_aug(conf_sample_clean, n_aug_max, adaptive_augmentation_strength)\n","\n","    # Perform the augmentations and put it on a list together with the original sample\n","    inputs = [preprocess_step2(preprocess_step1_test(image))] + [tr_transforms(image) for _ in range(n_aug)]\n","    # Stack the augmented and the original samples on a single tensor where the first dimension now is number of augmentations + 1\n","    inputs = torch.stack(inputs).to(device)\n","    # Zero the gradient\n","    optimizer.zero_grad()\n","    # Compute the output of the model given the inputs\n","    outputs = model(inputs)\n","    # Compute the loss\n","    loss = criterion(outputs)\n","    # Compute the gradient\n","    loss.backward()\n","    # Update the model parameters, SGD step\n","    optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"c5giIiKx73eA"},"source":["### Test function\n","The `test_single` function, given a single sample and the relative ground truth label, checks if the label predicted by the model is the same as the ground truth. Returns 1 if true, 0 if false."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YvTTUN8c73eA"},"outputs":[],"source":["# Function for testing the model on a single sample and checking if the label predicted is the same as the ground truth\n","def test_single(model, image, label):\n","    model.eval()\n","    with torch.no_grad():\n","        image = preprocess_step1_test(image)\n","        image = preprocess_step2(image)\n","        outputs = model(image.unsqueeze(0).to(device))\n","        _, predicted = torch.max(outputs.data, 1)\n","        result = 1 if (predicted == label) else 0\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"V1uRGo7f73eB"},"source":["## Loss Function / Criterion\n","\n","Since we don't have access to the labels at test-time, we need an unsupervised loss function.\n","We use the marginal entropy loss. This loss is computed on the aggregated probabilities of the augmented data, encouraging the model to make the same (confident) prediction across multiple augmentations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbq3fBH373eB"},"outputs":[],"source":["# This function is the loss function or criterion used\n","def marginal_entropy(outputs):\n","    # Normalize the logits by computing the log-softmax\n","    logits = outputs - outputs.logsumexp(dim=-1, keepdim=True)\n","    # Aggregate the log-probabilities across the batch and normalize by the batch size\n","    avg_logits = logits.logsumexp(dim=0) - np.log(logits.shape[0])\n","    # Compute the marginal entropy by multiplying the log-probabilities with the probabilities\n","    return -(avg_logits * torch.exp(avg_logits)).sum(dim=-1)"]},{"cell_type":"markdown","metadata":{"id":"qhCNTWXt73eB"},"source":["## Main TTA loop\n","We perform a loop, iterating over all samples, where for each sample we:\n","- Compute if the model correctly predicts the label of the sample (after doing this over all samples we can get the **accuracy** of the model).\n","- Compute augmentations and update the model.\n","- Again compute if the model correctly predicts the label of the sample.\n","\n","It is important to note that the first and third steps are performed only to evaluate the performance difference caused by the adapatation step. The TTA procedure doesn't need the labels.\n","\n","By doing this we can check if the process of updating the model to make the same confident predictions gives us an useful increment in accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JQ92BKC73eB"},"outputs":[],"source":["import torch.nn as nn\n","from tqdm import tqdm\n","\n","softmax = nn.Softmax(dim=1)\n","\n","def tta(model, subset):\n","\n","    model.to(device)\n","    model.eval()\n","\n","    #  For the optimizer we use Stochastic Gradient Descent\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.005)\n","\n","    tot_outputs_augm = 0.0\n","    tot_outputs_clean = 0.0\n","    running_average_sample_number = 0\n","\n","    # We iterate over all samples, one iteration for sample\n","    with tqdm(total=num_samples) as pbar:\n","        for i in range(num_samples):\n","            # Retrieve the image and respective label from the subset\n","            image, label = subset [i]\n","            # We reset the model for each sample\n","            reset_model(model, initial_state)\n","\n","            # Test if the model correctly predicts the label of the sample\n","            output_sample_clean = test_single(model, image, label)\n","            # Sum all results, after the training we average to get the accuracy\n","            tot_outputs_clean = tot_outputs_clean + output_sample_clean\n","\n","            # Compute the confidence of the model on its prediction\n","            conf_sample_clean = torch.max(softmax(model(preprocess_step2(preprocess_step1_test(image)).unsqueeze(0).to(device))), dim=1).values[0]\n","            # If the confidence is over 0.7 we skip altogether the augmentation and optimization step\n","            if(conf_sample_clean<0.7):\n","                # Adapt loop, computes the loss of output of the augmentations and updates the model\n","                adapt_single(model, image, optimizer, marginal_entropy,\n","                    conf_sample_clean, n_aug_max=16, adaptive_augmentation_strength = True)\n","\n","            # Test again if the model correctly predicts the label of the sample\n","            output_sample_augm = test_single(model, image, label)\n","            # Sum all results, after the training we average to get the accuracy\n","            tot_outputs_augm = tot_outputs_augm + output_sample_augm\n","\n","            # Some accuracy statistics to be visualized mid-run\n","            running_average_sample_number +=1\n","            running_average_original = tot_outputs_clean/running_average_sample_number\n","            running_average_augmented = tot_outputs_augm/running_average_sample_number\n","            difference = (running_average_augmented - running_average_original) * 100\n","            # Update progress bar with difference\n","            pbar.set_postfix({\n","            'Difference': f'{difference:.1f} %'\n","            })\n","            pbar.update(1)\n","\n","    print(\"Original accuracy over all samples:\", tot_outputs_clean/num_samples)\n","    print(\"Accuracy after adaptation over all samples:\", tot_outputs_augm/num_samples)\n","    print(\"Difference in accuracy over all samples:\", f'{(tot_outputs_augm/num_samples - tot_outputs_clean/num_samples)*100:.1f} %')\n"]},{"cell_type":"markdown","metadata":{"id":"870z6Xw173eC"},"source":["We run the TTA."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tzg2e87Q73eC"},"outputs":[],"source":["# Run the tta\n","tta(model, subset_dataset)"]},{"cell_type":"markdown","metadata":{"id":"Ut26JhXK73eC"},"source":["## Results"]},{"cell_type":"markdown","metadata":{"id":"NETILZ3X73eC"},"source":["We performed multiple runs of the code with different numbers of augmentations.\n","\n","- We decided to set a treshold for when to apply the adaptation step on the sample to confidence <0.7 as we observed that the accuracy remained the same but the computation time was reduced.\n","\n","- After trying different augmentations with different level of strength, we found a good tradeoff with the ones presented.\n","\n","- We introduced an adaptive mechanism for selecting the number of augmentations based on the confidence level. This approach produced very similar accuracy results while saving computational time, especially when dealing with a high number of augmentations.\n","\n","The performances are shown in the table.\n","- The baseline accuracy for the *Resnet50d* on the *Imagenet-V2 matched frequency* dataset is 69.2%.\n","- The difference in accuracy is represented as a percentage, where a positive value means that the accuracy increases after the adaptation step.\n","- We represent the data relative to the number of augmentations performed and annotate if the adaptive augmentation strength was set to *True*.\n","- We also take note of the time it takes to compute, represented as iterations per second (it/s)(using an Nvidia T4 GPU).\n","\n","|Number of augmentations|Difference|Time to compute|Adaptive augmentation strength|\n","|---|---|---|---|\n","|1|0 %|12 it/s|False|\n","|2|0.7 %|11.27 it/s|False|\n","|4|0.8 %|9.96 it/s|False|\n","|8|0.7 %|8.17  it/s|False|\n","|16|1.1 %|5.89 it/s|False|\n","|32|1.6 %|3.89 it/s|False|\n","|32|1.5 %|4.96 it/s|True|\n","|64|1.5 %|2.23 it/s|False|\n","|64|1.6 %|3.27 it/s|True|\n","\n","We can see that by increasing the number of augmentations we can achieve a better accuracy, at the cost of using more computing time. It is also noticeable the reduction in computing time when using the adaptive augmentation strength, while still having acceptable accuracy."]},{"cell_type":"markdown","metadata":{"id":"Pu1OLzPM73eC"},"source":["#### Different techniques we tried that didn't give an increase in performance:\n","\n","During the realization of this project, we used different techniques and performed multiple experiments, some of which didn't bring an increase in performance. Some of them were based on:\n","\n","- Different sets of augmentations for different levels of confidence, following the idea that we could apply more disruptive augmentations on low confidence samples.\n","\n","- Different levels of strength of the augmentations for difference levels of confidence.\n","\n","- Using the sample and the augmentations to build a sort of batch and compute batch normalization with the relative mean and variance.\n","\n","- For each augmentation, after passing it in the model but before using it to calculate the marginal entropy, the augmentation confidence was checked and if it was not above a certain treshold it was discarded. So in this case the marginal entropy was computed using only augmentations with confidence above the threshold. In the case there were no augmentations above the threshold, the adapt step was skipped and the original sample prediction was considered.\n","\n","- During TTA, samples with low confidence were temporarly skipped and grouped together. After iterating over all the samples, the adapt step was performed on this low confidence group either without resetting the model or by performing multiple cycles of the adaptation step for each sample.\n","\n","- Using the confidence gap (difference between the two highest confidence of predictions) over certain thresholds instead of using the confidence level."]},{"cell_type":"markdown","metadata":{"id":"UoCYCX5x73eD"},"source":["## Conclusions"]},{"cell_type":"markdown","metadata":{"id":"OFPhl61673eD"},"source":["In this project, we demonstrated the effectiveness of Test Time Adaptation using augmentations in improving the model accuracy and robustness.\n","\n","With this approach a tradeoff between the computational time and the increment in accuracy can be selected.\n","\n","TTA, being a technique applied at test time without any additional information coming with the samples, cannot provide drastical improvement in accuracy. It still remains an useful and easy to implement technique."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":0}
